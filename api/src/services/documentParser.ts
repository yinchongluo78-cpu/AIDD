import { PrismaClient } from '@prisma/client'
import axios from 'axios'
import { getSignedUrl } from './oss'
import pdfParse from 'pdf-parse'
import mammoth from 'mammoth'

const prisma = new PrismaClient()

// åˆ‡ç‰‡å¤§å°ï¼ˆçº¦400å­—ï¼‰
const CHUNK_SIZE = 400
const CHUNK_OVERLAP = 50 // é‡å éƒ¨åˆ†ï¼Œä¿è¯ä¸Šä¸‹æ–‡è¿è´¯

/**
 * è§£æå¹¶å­˜å‚¨æ–‡æ¡£å†…å®¹åˆ°chunks
 */
export async function parseAndStoreDocument(documentId: string, documentUrl: string) {
  try {
    console.log(`å¼€å§‹è§£ææ–‡æ¡£: ${documentId}`)

    // è·å–æ–‡æ¡£ä¿¡æ¯ï¼Œåˆ¤æ–­æ–‡ä»¶ç±»å‹
    const document = await prisma.kbDocument.findUnique({
      where: { id: documentId }
    })

    if (!document) {
      throw new Error('æ–‡æ¡£ä¸å­˜åœ¨')
    }

    const isPdf = document.fileExt?.toLowerCase() === '.pdf' ||
                  document.filename?.toLowerCase().endsWith('.pdf')
    const isDocx = document.fileExt?.toLowerCase().includes('wordprocessingml') ||
                   document.filename?.toLowerCase().endsWith('.docx')

    console.log(`æ–‡ä»¶ç±»å‹: ${isPdf ? 'PDF' : isDocx ? 'DOCX' : 'æ–‡æœ¬æ–‡ä»¶'}`)

    // è·å–æ–‡æ¡£å†…å®¹
    let content = ''

    // å¦‚æœæ˜¯OSS URLï¼Œéœ€è¦å…ˆç”Ÿæˆç­¾åURLå†ä¸‹è½½
    if (documentUrl.startsWith('http')) {
      // ä»OSS URLä¸­æå–key
      let ossKey = documentUrl
      if (documentUrl.includes('aliyuncs.com/')) {
        ossKey = documentUrl.split('aliyuncs.com/')[1].split('?')[0] // ç§»é™¤URLå‚æ•°
      }

      // ç”Ÿæˆç­¾åURLï¼ˆ1å°æ—¶æœ‰æ•ˆæœŸï¼‰
      const signedUrl = await getSignedUrl(ossKey, 3600)
      console.log('ä½¿ç”¨ç­¾åURLä¸‹è½½æ–‡æ¡£:', signedUrl.substring(0, 100) + '...')

      if (isPdf) {
        // PDFæ–‡ä»¶ï¼šä¸‹è½½ä¸ºbuffer
        const response = await axios.get(signedUrl, {
          responseType: 'arraybuffer',
          timeout: 60000 // PDFæ–‡ä»¶å¯èƒ½è¾ƒå¤§ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´
        })
        console.log(`PDFæ–‡ä»¶ä¸‹è½½å®Œæˆï¼Œå¤§å°: ${(response.data.length / 1024 / 1024).toFixed(2)}MB`)

        // ä½¿ç”¨pdf-parseè§£æ
        const pdfData = await pdfParse(response.data)
        content = pdfData.text
        console.log(`PDFè§£æå®Œæˆï¼Œæå–æ–‡æœ¬é•¿åº¦: ${content.length}`)
        console.log(`PDFä¿¡æ¯ - é¡µæ•°: ${pdfData.numpages}, æ–‡æœ¬é¢„è§ˆ: ${content.substring(0, 200)}`)
      } else if (isDocx) {
        // DOCXæ–‡ä»¶ï¼šä¸‹è½½ä¸ºbuffer
        const response = await axios.get(signedUrl, {
          responseType: 'arraybuffer',
          timeout: 60000
        })
        console.log(`DOCXæ–‡ä»¶ä¸‹è½½å®Œæˆï¼Œå¤§å°: ${(response.data.length / 1024 / 1024).toFixed(2)}MB`)

        // ä½¿ç”¨mammothè§£æ
        const result = await mammoth.extractRawText({ buffer: response.data })
        content = result.value
        console.log(`DOCXè§£æå®Œæˆï¼Œæå–æ–‡æœ¬é•¿åº¦: ${content.length}`)
        console.log(`DOCXæ–‡æœ¬é¢„è§ˆ: ${content.substring(0, 200)}`)
      } else {
        // æ–‡æœ¬æ–‡ä»¶ï¼šä¿æŒåŸæœ‰é€»è¾‘
        const response = await axios.get(signedUrl, {
          responseType: 'text',
          timeout: 30000
        })
        content = response.data
      }
    } else {
      // æœ¬åœ°æ–‡ä»¶è·¯å¾„ - éœ€è¦å¤„ç†ç›¸å¯¹è·¯å¾„
      const fs = require('fs').promises
      const path = require('path')

      let fullPath = documentUrl
      // å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œæ‹¼æ¥å®Œæ•´è·¯å¾„
      if (documentUrl.startsWith('/uploads/')) {
        fullPath = path.join(__dirname, '../../', documentUrl)
      }

      console.log(`å°è¯•è¯»å–æ–‡ä»¶: ${fullPath}`)

      if (isPdf) {
        // PDFæ–‡ä»¶ï¼šè¯»å–ä¸ºbuffer
        const dataBuffer = await fs.readFile(fullPath)
        const pdfData = await pdfParse(dataBuffer)
        content = pdfData.text
        console.log(`PDFè§£æå®Œæˆï¼Œæå–æ–‡æœ¬é•¿åº¦: ${content.length}`)
      } else if (isDocx) {
        // DOCXæ–‡ä»¶ï¼šè¯»å–ä¸ºbuffer
        const dataBuffer = await fs.readFile(fullPath)
        const result = await mammoth.extractRawText({ buffer: dataBuffer })
        content = result.value
        console.log(`DOCXè§£æå®Œæˆï¼Œæå–æ–‡æœ¬é•¿åº¦: ${content.length}`)
      } else {
        // æ–‡æœ¬æ–‡ä»¶ï¼šä¿æŒåŸæœ‰é€»è¾‘
        content = await fs.readFile(fullPath, 'utf-8')
        console.log(`æ–‡ä»¶è¯»å–æˆåŠŸï¼Œå†…å®¹é•¿åº¦: ${content.length}`)
      }
    }

    // æ¸…ç†å†…å®¹
    content = cleanContent(content)

    // åˆ›å»ºæ–‡æ¡£åˆ‡ç‰‡
    const chunks = createChunks(content, CHUNK_SIZE, CHUNK_OVERLAP)

    console.log(`æ–‡æ¡£åˆ†å‰²æˆ ${chunks.length} ä¸ªåˆ‡ç‰‡`)

    // æ‰¹é‡å­˜å‚¨åˆ‡ç‰‡åˆ°æ•°æ®åº“
    const chunkPromises = chunks.map((chunk, index) =>
      prisma.kbChunk.create({
        data: {
          docId: documentId,
          content: chunk,
          seq: index
        }
      })
    )

    await Promise.all(chunkPromises)
    console.log(`æˆåŠŸå­˜å‚¨ ${chunks.length} ä¸ªåˆ‡ç‰‡åˆ°æ•°æ®åº“`)

    // æ›´æ–°æ–‡æ¡£çŠ¶æ€ä¸ºå·²è§£æ
    await prisma.kbDocument.update({
      where: { id: documentId },
      data: { status: 'parsed' }
    })

    return chunks.length
  } catch (error) {
    console.error('è§£ææ–‡æ¡£å¤±è´¥:', error)
    // æ›´æ–°æ–‡æ¡£çŠ¶æ€ä¸ºè§£æå¤±è´¥
    await prisma.kbDocument.update({
      where: { id: documentId },
      data: { status: 'failed' }
    })
    throw error
  }
}

/**
 * æ¸…ç†æ–‡æ¡£å†…å®¹
 */
function cleanContent(content: string): string {
  // ç§»é™¤å¸¸è§çš„é¡µçœ‰é¡µè„šæ¨¡å¼
  content = content.replace(/ç¬¬\s*\d+\s*é¡µ/g, '')
  content = content.replace(/Page\s*\d+/gi, '')

  // ç§»é™¤ç›®å½•ç›¸å…³çš„ç‚¹çº¿
  content = content.replace(/\.{3,}/g, '')

  // ç§»é™¤å¤šä½™çš„æ¢è¡Œ(ä¿ç•™å•æ¢è¡Œå’ŒåŒæ¢è¡Œ)
  content = content.replace(/\n{3,}/g, '\n\n')

  // åªç§»é™¤è¡Œé¦–è¡Œå°¾çš„ç©ºç™½,ä¸å¤„ç†ä¸­é—´çš„ç©ºç™½(é¿å…å¤§æ–‡æœ¬æ€§èƒ½é—®é¢˜)
  content = content.split('\n').map(line => line.trim()).join('\n')

  return content.trim()
}

/**
 * å°†æ–‡æ¡£å†…å®¹åˆ†å‰²æˆåˆ‡ç‰‡
 */
function createChunks(content: string, chunkSize: number, overlap: number): string[] {
  const chunks: string[] = []
  let start = 0

  while (start < content.length) {
    let end = start + chunkSize

    // å°è¯•åœ¨å¥å­è¾¹ç•Œç»“æŸ
    if (end < content.length) {
      const lastPeriod = content.lastIndexOf('ã€‚', end)
      const lastExclamation = content.lastIndexOf('ï¼', end)
      const lastQuestion = content.lastIndexOf('ï¼Ÿ', end)
      const lastNewline = content.lastIndexOf('\n', end)

      const boundaries = [lastPeriod, lastExclamation, lastQuestion, lastNewline].filter(i => i > start)

      if (boundaries.length > 0) {
        end = Math.max(...boundaries) + 1
      }
    }

    const chunk = content.substring(start, end).trim()
    if (chunk) {
      chunks.push(chunk)
    }

    // ä¸‹ä¸€ä¸ªåˆ‡ç‰‡çš„èµ·å§‹ä½ç½®ï¼ˆè€ƒè™‘é‡å ï¼‰
    start = end - overlap
  }

  return chunks
}

/**
 * è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆæ”¹è¿›çš„å…³é”®è¯åŒ¹é…ï¼‰
 */
function calculateRelevanceScore(query: string, content: string): number {
  const queryTokens = tokenize(query)
  const contentTokens = tokenize(content)

  if (queryTokens.length === 0 || contentTokens.length === 0) return 0

  let score = 0
  const contentLower = content.toLowerCase()

  queryTokens.forEach(token => {
    // å®Œå…¨åŒ¹é…å¾—åˆ†æ›´é«˜
    const exactMatches = (contentLower.match(new RegExp(token, 'g')) || []).length
    score += exactMatches * 2

    // éƒ¨åˆ†åŒ¹é…ä¹Ÿç»™åˆ†
    contentTokens.forEach(cToken => {
      if (cToken.includes(token) || token.includes(cToken)) {
        score += 0.5
      }
    })
  })

  // å½’ä¸€åŒ–åˆ†æ•°ï¼ˆè€ƒè™‘æŸ¥è¯¢é•¿åº¦ï¼‰
  return score / queryTokens.length
}

/**
 * åˆ†è¯å‡½æ•°ï¼ˆæ”¹è¿›ç‰ˆ - æ”¯æŒä¸­æ–‡ï¼‰
 */
function tokenize(text: string): string[] {
  const tokens: string[] = []

  // æ¸…ç†æ–‡æœ¬,åªä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—
  const cleaned = text.toLowerCase().replace(/[^\u4e00-\u9fa5a-z0-9\s]/g, ' ')

  // æå–è‹±æ–‡å•è¯(æŒ‰ç©ºæ ¼åˆ†å‰²)
  const englishWords = cleaned.match(/[a-z0-9]+/g) || []
  tokens.push(...englishWords.filter(w => w.length > 1))

  // æå–ä¸­æ–‡è¯ç»„(2-4å­—)
  const chineseText = cleaned.replace(/[a-z0-9\s]/g, '')
  for (let i = 0; i < chineseText.length; i++) {
    // æå–2å­—è¯
    if (i + 1 < chineseText.length) {
      tokens.push(chineseText.substring(i, i + 2))
    }
    // æå–3å­—è¯
    if (i + 2 < chineseText.length) {
      tokens.push(chineseText.substring(i, i + 3))
    }
    // æå–4å­—è¯
    if (i + 3 < chineseText.length) {
      tokens.push(chineseText.substring(i, i + 4))
    }
  }

  // å»é‡
  return [...new Set(tokens)]
}

/**
 * æœç´¢ç›¸å…³çš„æ–‡æ¡£åˆ‡ç‰‡ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
 */
export async function searchDocumentChunks(
  query: string,
  categoryId?: string,
  userId?: string,
  limit: number = 5,
  documentIds?: string[]
): Promise<Array<{chunk: any, document: any, score: number}>> {
  try {
    console.log('=== çŸ¥è¯†åº“æ£€ç´¢ ===')
    console.log('æŸ¥è¯¢:', query)
    console.log('åˆ†ç±»ID:', categoryId || 'æ— ')
    console.log('æ–‡æ¡£IDs:', documentIds?.length || 0)

    // æ„å»ºæŸ¥è¯¢æ¡ä»¶
    const whereClause: any = {}

    if (categoryId || userId || documentIds) {
      whereClause.document = {}
      if (categoryId) {
        whereClause.document.categoryId = categoryId
      }
      if (userId) {
        whereClause.document.userId = userId
      }
      if (documentIds && documentIds.length > 0) {
        whereClause.document.id = {
          in: documentIds
        }
      }
    }

    // æ£€æµ‹æ˜¯å¦æ˜¯æ¦‚è¿°æ€§é—®é¢˜ï¼ˆå¸Œæœ›äº†è§£æ–‡æ¡£æ•´ä½“å†…å®¹ï¼‰
    const isSummaryQuery = /è®²äº†ä»€ä¹ˆ|æœ‰ä»€ä¹ˆå†…å®¹|ä¸»è¦å†…å®¹|æ€»ç»“|æ¦‚æ‹¬|ä»‹ç»|å¤§çº²|ç›®å½•/.test(query)

    if (isSummaryQuery && documentIds && documentIds.length > 0) {
      console.log('ğŸ” æ£€æµ‹åˆ°æ¦‚è¿°æ€§é—®é¢˜ï¼Œè¿”å›æ–‡æ¡£å¼€å¤´éƒ¨åˆ†ä¾›å¤§æ¨¡å‹ç†è§£')

      // è¿”å›æ–‡æ¡£å¼€å¤´éƒ¨åˆ†ï¼Œè®©å¤§æ¨¡å‹åŸºäºå®Œæ•´å†…å®¹å›ç­”
      const summaryChunks = await prisma.kbChunk.findMany({
        where: {
          document: {
            id: {
              in: documentIds
            }
          }
        },
        include: {
          document: true
        },
        orderBy: {
          seq: 'asc'
        },
        take: limit * 2 // æ¦‚è¿°æ€§é—®é¢˜è¿”å›æ›´å¤šå†…å®¹
      })

      console.log(`è¿”å› ${summaryChunks.length} ä¸ªæ–‡æ¡£å¼€å¤´åˆ‡ç‰‡ä¾›å¤§æ¨¡å‹åˆ†æ`)

      return summaryChunks.map(chunk => ({
        chunk,
        document: chunk.document,
        score: 1.0 // æ¦‚è¿°æ€§æŸ¥è¯¢ç»™äºˆé«˜åˆ†
      }))
    }

    // æå–å…³é”®è¯è¿›è¡Œç²¾ç¡®æ£€ç´¢
    const keywords = tokenize(query)
    console.log('æå–å…³é”®è¯:', keywords)

    if (keywords.length > 0) {
      // ä½¿ç”¨ORæ¡ä»¶åŒ¹é…ä»»æ„å…³é”®è¯
      whereClause.OR = keywords.map(keyword => ({
        content: {
          contains: keyword,
          mode: 'insensitive'
        }
      }))
    }

    // è·å–æ‰€æœ‰åŒ¹é…çš„åˆ‡ç‰‡
    const chunks = await prisma.kbChunk.findMany({
      where: whereClause,
      include: {
        document: true
      },
      take: limit * 3, // å…ˆå–æ›´å¤šç»“æœï¼Œåé¢é‡æ–°æ’åº
    })

    console.log(`æ‰¾åˆ° ${chunks.length} ä¸ªåˆæ­¥åŒ¹é…çš„åˆ‡ç‰‡`)

    // å¦‚æœç²¾ç¡®æ£€ç´¢å¤±è´¥ï¼Œä¸”æœ‰æŒ‡å®šæ–‡æ¡£ï¼Œè¿”å›æ–‡æ¡£å¼€å¤´è®©å¤§æ¨¡å‹ç†è§£
    if (chunks.length === 0 && documentIds && documentIds.length > 0) {
      console.log('âš ï¸ æœªæ‰¾åˆ°å…³é”®è¯åŒ¹é…ï¼Œè¿”å›æ–‡æ¡£å¼€å¤´éƒ¨åˆ†è®©å¤§æ¨¡å‹ç†è§£ä¸Šä¸‹æ–‡')

      const fallbackChunks = await prisma.kbChunk.findMany({
        where: {
          document: {
            id: {
              in: documentIds
            }
          }
        },
        include: {
          document: true
        },
        orderBy: {
          seq: 'asc'
        },
        take: limit
      })

      console.log(`è¿”å› ${fallbackChunks.length} ä¸ªæ–‡æ¡£å¼€å¤´åˆ‡ç‰‡`)

      return fallbackChunks.map(chunk => ({
        chunk,
        document: chunk.document,
        score: 0.3 // ç»™äºˆä¸­ç­‰åˆ†æ•°
      }))
    }

    // è®¡ç®—ç›¸å…³æ€§åˆ†æ•°å¹¶æ’åº
    const rankedChunks = chunks
      .map(chunk => ({
        chunk,
        document: chunk.document,
        score: calculateRelevanceScore(query, chunk.content)
      }))
      .sort((a, b) => b.score - a.score) // æŒ‰åˆ†æ•°é™åº
      .slice(0, limit) // å–top N

    console.log('æœ€ç»ˆè¿”å›åˆ‡ç‰‡æ•°:', rankedChunks.length)
    if (rankedChunks.length > 0) {
      console.log('æœ€é«˜åˆ†æ•°:', rankedChunks[0].score)
      console.log('æœ€é«˜åˆ†åˆ‡ç‰‡é¢„è§ˆ:', rankedChunks[0].chunk.content.substring(0, 100))
    }

    return rankedChunks
  } catch (error) {
    console.error('æœç´¢æ–‡æ¡£åˆ‡ç‰‡å¤±è´¥:', error)
    return []
  }
}
